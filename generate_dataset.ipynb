{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from utils import Timer\n",
    "from joblib import Parallel, delayed\n",
    "from traj2grid import Traj2Grid\n",
    "import traj_dist.distance as tdist\n",
    "from parameters import *\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data start\n",
      "read data/full/gps_20161101 done, 1.181s after read data start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1805870532989502"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timer = Timer()\n",
    "\n",
    "file_path = \"data/full/gps_20161101\"\n",
    "dict_path = \"data/str_grid2idx_400_44612.json\"\n",
    "nrows = 2000000\n",
    "vocab_size = 400\n",
    "\n",
    "\n",
    "# read data\n",
    "timer.tik(\"read data\")\n",
    "df = pd.read_csv(file_path, names=[\"name\", \"id\", \"time\", \"lon\", \"lat\"],\n",
    "        usecols=[\"id\", \"lon\", \"lat\"], nrows=nrows)\n",
    "timer.tok(\"read {}\".format(file_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 去除超出范围的数据点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剩1895778/2000000个点，筛掉5%\n"
     ]
    }
   ],
   "source": [
    "pad = 0.002\n",
    "\n",
    "l = len(df)\n",
    "df = df[(df[\"lon\"] > 104.04214 + pad) & (df[\"lon\"] < 104.12958 - pad)]\n",
    "df = df[(df[\"lat\"] > 30.65294 + pad) & (df[\"lat\"] < 30.72775 - pad)]\n",
    "print(f\"剩{len(df)}/{l}个点，筛掉{round(100 - 100 * len(df) / l)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GroupBy转换为1维点列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dictdata/str_grid2idx_400_44612.json done, 15.079s after read data start\n",
      "group-apply done, 113.32s after read data start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "113.320148229599"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_grid2idx = json.load(open(dict_path))\n",
    "t2g = Traj2Grid(row_num, column_num, min_lon, min_lat, max_lon, max_lat)\n",
    "grid2idx = {eval(g): str_grid2idx[g] for g in list(str_grid2idx)}\n",
    "t2g.set_vocab(grid2idx)\n",
    "timer.tok(f\"load dict{dict_path}\")\n",
    "\n",
    "\n",
    "def group_concat(group: pd.DataFrame):\n",
    "    origin_traj = [((row[\"lon\"]), row[\"lat\"])\n",
    "                   for index, row in group.iterrows()]\n",
    "    traj_1d, coord_traj = t2g.convert1d(origin_traj)\n",
    "    series = pd.Series({\n",
    "        \"origin_trajs\": coord_traj,\n",
    "        \"trajs\": traj_1d,\n",
    "        \"len\": len(traj_1d),\n",
    "        \"max_lon\": group[\"lon\"].max(),\n",
    "        \"max_lat\": group[\"lat\"].max(),\n",
    "        \"min_lon\": group[\"lon\"].min(),\n",
    "        \"min_lat\": group[\"lat\"].min(),\n",
    "    })\n",
    "    return series\n",
    "\n",
    "res = Parallel(n_jobs=44)(delayed(group_concat)(group)for name, group in df.groupby(\"id\"))\n",
    "df = pd.DataFrame(res)\n",
    "timer.tok(\"group-apply\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 过滤0长度轨迹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "剩10955/10955条轨迹，筛掉0%\n"
     ]
    }
   ],
   "source": [
    "dff = df[(df[\"len\"] > 0)]\n",
    "print(f\"剩{len(dff)}/{len(df)}条轨迹，筛掉{round(100 - 100 * len(dff) / len(df))}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成pair-wise轨迹距离矩阵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-0.0% done, 6698.401s after read data start\n",
      "101-0.01% done, 6699.247s after read data start\n",
      "201-0.03% done, 6699.943s after read data start\n",
      "301-0.08% done, 6700.931s after read data start\n",
      "401-0.13% done, 6702.526s after read data start\n",
      "501-0.21% done, 6704.544s after read data start\n",
      "601-0.3% done, 6706.832s after read data start\n",
      "701-0.41% done, 6709.584s after read data start\n",
      "801-0.53% done, 6712.513s after read data start\n",
      "901-0.68% done, 6715.818s after read data start\n",
      "1001-0.84% done, 6719.786s after read data start\n",
      "1101-1.01% done, 6724.256s after read data start\n",
      "1201-1.2% done, 6728.53s after read data start\n",
      "1301-1.41% done, 6734.16s after read data start\n",
      "1401-1.64% done, 6740.227s after read data start\n",
      "1501-1.88% done, 6747.025s after read data start\n",
      "1601-2.14% done, 6753.494s after read data start\n",
      "1701-2.41% done, 6760.741s after read data start\n",
      "1801-2.7% done, 6767.807s after read data start\n",
      "1901-3.01% done, 6775.829s after read data start\n",
      "2001-3.34% done, 6784.131s after read data start\n",
      "2101-3.68% done, 6792.932s after read data start\n",
      "2201-4.04% done, 6802.034s after read data start\n",
      "2301-4.41% done, 6811.207s after read data start\n",
      "2401-4.8% done, 6821.079s after read data start\n",
      "2501-5.21% done, 6831.441s after read data start\n",
      "2601-5.64% done, 6842.071s after read data start\n",
      "2701-6.08% done, 6852.491s after read data start\n",
      "2801-6.54% done, 6863.695s after read data start\n",
      "2901-7.01% done, 6875.301s after read data start\n",
      "3001-7.51% done, 6887.237s after read data start\n",
      "3101-8.01% done, 6899.978s after read data start\n",
      "3201-8.54% done, 6912.494s after read data start\n",
      "3301-9.08% done, 6924.729s after read data start\n",
      "3401-9.64% done, 6937.815s after read data start\n",
      "3501-10.22% done, 6950.77s after read data start\n",
      "3601-10.81% done, 6963.641s after read data start\n",
      "3701-11.42% done, 6977.792s after read data start\n",
      "3801-12.04% done, 6992.796s after read data start\n",
      "3901-12.68% done, 7008.429s after read data start\n",
      "4001-13.34% done, 7023.514s after read data start\n",
      "4101-14.02% done, 7038.243s after read data start\n",
      "4201-14.71% done, 7054.966s after read data start\n",
      "4301-15.42% done, 7072.336s after read data start\n",
      "4401-16.14% done, 7090.388s after read data start\n",
      "4501-16.88% done, 7108.648s after read data start\n",
      "4601-17.64% done, 7127.894s after read data start\n",
      "4701-18.42% done, 7148.156s after read data start\n",
      "4801-19.21% done, 7169.433s after read data start\n",
      "4901-20.02% done, 7189.594s after read data start\n",
      "5001-20.84% done, 7210.226s after read data start\n",
      "5101-21.69% done, 7231.96s after read data start\n",
      "5201-22.54% done, 7253.815s after read data start\n",
      "5301-23.42% done, 7278.417s after read data start\n",
      "5401-24.31% done, 7303.233s after read data start\n",
      "5501-25.22% done, 7326.824s after read data start\n",
      "5601-26.14% done, 7351.59s after read data start\n",
      "5701-27.09% done, 7378.508s after read data start\n",
      "5801-28.05% done, 7404.837s after read data start\n",
      "5901-29.02% done, 7432.044s after read data start\n",
      "6001-30.01% done, 7459.187s after read data start\n",
      "6101-31.02% done, 7488.672s after read data start\n",
      "6201-32.05% done, 7517.256s after read data start\n",
      "6301-33.09% done, 7547.775s after read data start\n",
      "6401-34.15% done, 7581.306s after read data start\n",
      "6501-35.22% done, 7612.487s after read data start\n",
      "6601-36.31% done, 7645.542s after read data start\n",
      "6701-37.42% done, 7677.867s after read data start\n",
      "6801-38.55% done, 7711.887s after read data start\n",
      "6901-39.69% done, 7748.479s after read data start\n",
      "7001-40.85% done, 7783.213s after read data start\n",
      "7101-42.02% done, 7820.078s after read data start\n",
      "7201-43.22% done, 7857.218s after read data start\n",
      "7301-44.42% done, 7896.679s after read data start\n",
      "7401-45.65% done, 7936.865s after read data start\n",
      "7501-46.89% done, 7976.286s after read data start\n",
      "7601-48.15% done, 8018.72s after read data start\n",
      "7701-49.43% done, 8061.64s after read data start\n",
      "7801-50.72% done, 8104.09s after read data start\n",
      "7901-52.03% done, 8148.973s after read data start\n",
      "8001-53.35% done, 8192.782s after read data start\n",
      "8101-54.69% done, 8239.105s after read data start\n",
      "8201-56.05% done, 8286.6s after read data start\n",
      "8301-57.43% done, 8335.873s after read data start\n",
      "8401-58.82% done, 8386.899s after read data start\n",
      "8501-60.23% done, 8434.834s after read data start\n",
      "8601-61.65% done, 8484.515s after read data start\n",
      "8701-63.09% done, 8535.356s after read data start\n",
      "8801-64.55% done, 8588.037s after read data start\n",
      "8901-66.03% done, 8640.357s after read data start\n",
      "9001-67.52% done, 8693.116s after read data start\n",
      "9101-69.03% done, 8746.941s after read data start\n",
      "9201-70.55% done, 8802.971s after read data start\n",
      "9301-72.1% done, 8858.407s after read data start\n",
      "9401-73.66% done, 8916.56s after read data start\n",
      "9501-75.23% done, 8972.359s after read data start\n",
      "9601-76.82% done, 9031.422s after read data start\n",
      "9701-78.43% done, 9093.622s after read data start\n",
      "9801-80.06% done, 9155.292s after read data start\n",
      "9901-81.7% done, 9221.827s after read data start\n",
      "10001-83.36% done, 9284.821s after read data start\n",
      "10101-85.03% done, 9350.053s after read data start\n",
      "10201-86.72% done, 9416.424s after read data start\n",
      "10301-88.43% done, 9484.25s after read data start\n",
      "10401-90.16% done, 9550.758s after read data start\n",
      "10501-91.9% done, 9619.506s after read data start\n",
      "10601-93.66% done, 9689.299s after read data start\n",
      "10701-95.43% done, 9763.258s after read data start\n",
      "10801-97.23% done, 9838.403s after read data start\n",
      "10901-99.03% done, 9911.461s after read data start\n",
      "calculate distance done, 9949.119s after read data start\n"
     ]
    }
   ],
   "source": [
    "# dff = dff.reset_index()\n",
    "origin_trajs = dff[\"origin_trajs\"].to_list()\n",
    "arr = [np.array(origin_traj) for origin_traj in origin_trajs]\n",
    "length = len(arr)\n",
    "dis_matrix = np.zeros((length, length))\n",
    "dis_func = getattr(tdist, \"discret_frechet\")\n",
    "\n",
    "\n",
    "def cal_dis(i, j, x, y, n):\n",
    "    dis = dis_func(x, y)\n",
    "    if i == j + 1 and i % 100 == 1:\n",
    "        timer.tok(f'{i}-{round((i * i) / (n * n) * 100, 2)}%')\n",
    "    return i, j, dis\n",
    "\n",
    "res = Parallel(n_jobs=44)(\n",
    "    delayed(cal_dis)(i, j, arr[i], arr[j], length - 1) for i in range(length) for j in range(i))\n",
    "timer.tok(\"calculate distance\")\n",
    "for (i, j, dis) in res:\n",
    "    dis_matrix[i,j] = dis\n",
    "    dis_matrix[j,i] = dis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 生成 Train Dataset 第六步：保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save done, 13763.64s after read data start\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13763.640017032623"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full = True\n",
    "\n",
    "file_name = file_path.split(\"/\")[-1]\n",
    "save_path = \"data/test/\"\n",
    "file_path = save_path + file_name\n",
    "origin_trajs = dff[\"origin_trajs\"].to_list()\n",
    "dict_save = {'trajs': dff[\"trajs\"].to_list(), 'origin_trajs': origin_trajs}\n",
    "if full:\n",
    "    dict_save[\"dis_matrix\"] = dis_matrix.tolist()\n",
    "    json.dump(dict_save, open(file_path + f\"_{len(origin_trajs)}_{vocab_size}_dataset_full.json\", \"w\"))\n",
    "else:\n",
    "    json.dump(dict_save, open(file_path + f\"_{len(origin_trajs)}_{vocab_size}_dataset_small.json\", \"w\"))\n",
    "timer.tok(\"save\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

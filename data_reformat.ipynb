{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "用于对原始数据做基本的筛选和格式化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import Timer\n",
    "from joblib import Parallel, delayed\n",
    "from gcj2wgs import gcj02_to_wgs84 as gcj2wgs\n",
    "\n",
    "timer = Timer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def data_reformat(file_path):\n",
    "    timer.tik(\"read\")\n",
    "    df = pd.DataFrame(pd.read_csv(file_path, header=None))\n",
    "    df.columns = [\"name\", \"order_id\", \"time\", \"lon\", \"lat\"]  # lon经度 lat纬度\n",
    "    timer.tok()\n",
    "\n",
    "    def group_concat(name, x: pd.DataFrame):\n",
    "        traj_str = \"[\"\n",
    "        for index, row in x.iterrows():\n",
    "            traj_str += \"({} {}),\".format(row[\"lon\"], row[\"lat\"])\n",
    "        traj_str = traj_str[:-1]\n",
    "        traj_str += \"]\"\n",
    "        series = pd.Series(\n",
    "            {\n",
    "                \"order_id\": name,\n",
    "                \"traj\": traj_str,\n",
    "                \"len\": len(x),\n",
    "                \"max_time_diff\": x[\"time\"].diff().max(),\n",
    "                \"max_lon_diff\": x[\"lon\"].diff().max(),\n",
    "                \"max_lat_diff\": x[\"lat\"].diff().max(),\n",
    "            }\n",
    "        )\n",
    "        return series\n",
    "\n",
    "    def applyParallel(df_groups, func, n=6):\n",
    "        res = Parallel(n_jobs=n)(\n",
    "            delayed(func)(name, group) for name, group in df_groups\n",
    "        )\n",
    "        return pd.DataFrame(res)\n",
    "\n",
    "    # group-apply\n",
    "    timer.tik(\"group-apply\")\n",
    "    group_df = applyParallel(df.groupby(\"order_id\"), group_concat)\n",
    "    timer.tok()\n",
    "\n",
    "    # filter\n",
    "    t_diff_limit = 20\n",
    "    lon_lat_diff_limit = 0.005\n",
    "    f_group = group_df[\n",
    "        (group_df[\"max_time_diff\"] < t_diff_limit)\n",
    "        & (group_df[\"max_lon_diff\"] + group_df[\"max_lat_diff\"] < lon_lat_diff_limit)\n",
    "    ]\n",
    "    f_group = f_group[[\"order_id\", \"traj\"]]\n",
    "    f_group = f_group.set_index(\"order_id\")\n",
    "    print(\n",
    "        \"剩{}/{}条，筛掉{}%\".format(\n",
    "            len(f_group), len(group_df), round(100 - 100 * len(f_group) / len(group_df))\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # save\n",
    "    f_group.to_csv(file_path + \"_format\")\n",
    "    print(\"all done\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read start\n",
      "read done, 0.091s after read start\n",
      "group-apply start\n",
      "group-apply done, 0.918s after group-apply start\n",
      "剩428/574条，筛掉25%\n",
      "all done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_reformat(\"data/100k_gps_20161101\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

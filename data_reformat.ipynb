{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "用于对原始数据做基本的筛选和格式化"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import Timer\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "timer = Timer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def data_reformat(file_path):\n",
    "    timer.tik(\"read\")\n",
    "    df = pd.DataFrame(pd.read_csv(file_path, header=None))\n",
    "    df.columns = ['name', 'order_id', 'time', 'lon', 'lat']  # lon经度 lat纬度\n",
    "    timer.tok()\n",
    "\n",
    "    def group_concat(name, x: pd.DataFrame):\n",
    "        traj_str = \"\"\n",
    "        for index, row in x.iterrows():\n",
    "            traj_str += \"({} {}),\".format(row['lon'], row['lat'])\n",
    "        traj_str = traj_str[:-1]\n",
    "        series = pd.Series({'order_id': name,\n",
    "                            'traj': traj_str,\n",
    "                            'len': len(x),\n",
    "                            \"max_time_diff\": x['time'].diff().max(),\n",
    "                            'max_lon_diff': x['lon'].diff().max(),\n",
    "                            'max_lat_diff': x['lat'].diff().max()})\n",
    "        return series\n",
    "\n",
    "    def applyParallel(df_groups, func, n=6):\n",
    "        res = Parallel(n_jobs=n)(delayed(func)(name, group) for name, group in df_groups)\n",
    "        return pd.DataFrame(res)\n",
    "\n",
    "    # group-apply\n",
    "    timer.tik(\"group-apply\")\n",
    "    group_df = applyParallel(df.groupby(\"order_id\"), group_concat)\n",
    "    timer.tok()\n",
    "\n",
    "    # filter\n",
    "    t_diff_limit = 20\n",
    "    lon_lat_diff_limit = 0.005\n",
    "    f_group = group_df[(group_df['max_time_diff'] < t_diff_limit) & (\n",
    "            group_df['max_lon_diff'] + group_df['max_lat_diff'] < lon_lat_diff_limit)]\n",
    "    f_group = f_group[['order_id', 'traj', 'len']]\n",
    "    f_group = f_group.set_index('order_id')\n",
    "    print(\"剩{}/{}条，筛掉{}%\".format(len(f_group), len(group_df), round(100 - 100 * len(f_group) / len(group_df))))\n",
    "\n",
    "    # save\n",
    "    f_group.to_csv(file_path + \"_format\")\n",
    "    print(\"done\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read start\n",
      "read done:1.1561s\n",
      "group-apply start\n",
      "group-apply done:13.5368s\n",
      "剩4142/5650条，筛掉27%\n",
      "done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_reformat(\"data/1m_gps_20161101\")\n",
    "# for i in range(16, 31):\n",
    "#     day = str(i).zfill(2)\n",
    "#     print(\"day:{}\".format(day))\n",
    "#     file_path = r'data/cxwang@mail.xjtu.edu.cn_201611{}/gps_201611{}'.format(day, day)\n",
    "#     data_reformat(file_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}